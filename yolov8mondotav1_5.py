# -*- coding: utf-8 -*-
"""YOLOv8monDOTAv1.5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Qh263XCr9Dk7xfbA-EEdl8vRNwQHmly7
"""

import os
import zipfile
import time
import glob
import shutil
import yaml
from google.colab import drive

# --- 1. Mount Google Drive ---
try:
    print("Mounting Google Drive...")
    drive.mount('/content/drive', force_remount=True)
    print("Drive mounted successfully.\n")
except Exception as e:
    print(f"CRITICAL: Failed to mount drive: {e}")
    raise SystemExit("Cannot proceed without Google Drive.")

# --- 2. Helper Function: unzip_file ---
def unzip_file(zip_path, dest_path):
    """
    Extracts a zip file to a destination directory.
    """
    if not os.path.exists(zip_path):
        print(f"ERROR: File not found, skipping! {zip_path}\n")
        return

    print(f"Extracting '{os.path.basename(zip_path)}' to '{dest_path}'...")
    os.makedirs(dest_path, exist_ok=True)
    start_time = time.time()
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(dest_path)
        end_time = time.time()
        print(f"Done in {end_time - start_time:.2f} seconds.\n")
    except Exception as e:
        print(f"Error extracting {zip_path}: {e}\n")

# --- 3. Helper Function: fix_nested_files ---
def fix_nested_files(target_dir, file_extension):
    """
    Finds all files (e.g., .png) in subdirectories and moves them
    up to the target_dir, then removes the empty subdirs.
    """
    print(f"Scanning {target_dir} for nested files...")
    nested_files = glob.glob(os.path.join(target_dir, f"**/*{file_extension}"), recursive=True)

    files_moved = 0
    for file_path in nested_files:
        if os.path.dirname(file_path) == target_dir:
            continue
        try:
            shutil.move(file_path, target_dir)
            files_moved += 1
        except Exception as e:
            print(f"Could not move {file_path}: {e}")

    print(f"Moved {files_moved} nested files.")

    # Clean up empty subdirectories
    for dirpath, dirnames, filenames in os.walk(target_dir, topdown=False):
        if dirpath == target_dir:
            continue
        if not dirnames and not filenames:
            try:
                os.rmdir(dirpath)
                print(f"Removed empty directory: {dirpath}")
            except Exception as e:
                print(f"Could not remove empty dir {dirpath}: {e}")

# --- 4. Configuration ---
base_drive_path = "/content/drive/MyDrive/DOTA-v1.5"
base_dataset_path = "/content/DOTA_dataset"

files_to_unzip = [
    {"source": f"{base_drive_path}/train/images/part1.zip", "destination": f"{base_dataset_path}/train/images"},
    {"source": f"{base_drive_path}/train/images/part2.zip", "destination": f"{base_dataset_path}/train/images"},
    {"source": f"{base_drive_path}/train/images/part3.zip", "destination": f"{base_dataset_path}/train/images"},
    {"source": f"{base_drive_path}/train/labelTxt-v1.5/DOTA-v1.5_train_hbb.zip", "destination": f"{base_dataset_path}/train/labels"},
    {"source": f"{base_drive_path}/val/images/part1.zip", "destination": f"{base_dataset_path}/val/images"},
    {"source": f"{base_drive_path}/val/labelTxt-v1.5/DOTA-v1.5_val_hbb.zip", "destination": f"{base_dataset_path}/val/labels"},
    {"source": f"{base_drive_path}/images/part1.zip", "destination": f"{base_dataset_path}/test/images"},
    {"source": f"{base_drive_path}/images/part2.zip", "destination": f"{base_dataset_path}/test/images"},
]

# --- 5. Cleanup Previous Run ---
if os.path.exists(base_dataset_path):
    print("Cleaning up previous extraction...")
    shutil.rmtree(base_dataset_path)
    print("Cleanup complete.\n")

# --- 6. Run Extraction ---
print("--- Starting Final Dataset Extraction ---")
for item in files_to_unzip:
    unzip_file(item["source"], item["destination"])
print("--- All extraction tasks complete! ---")

# --- 7. Fix Nested Folders ---
print("\n--- Fixing nested folder structure ---")
fix_nested_files(f"{base_dataset_path}/train/images", ".png")
fix_nested_files(f"{base_dataset_path}/val/images", ".png")
fix_nested_files(f"{base_dataset_path}/test/images", ".png")
print("--- Nested folder fix complete! ---")

# --- 8. Create dota.yaml File (for v1.0 - 15 classes) ---
print("\n--- Creating dota.yaml file (15 Classes) ---")
data_yaml = {
    'path': '/content/DOTA_dataset',
    'train': 'train/images',
    'val': 'val/images',
    'test': 'test/images',

    # 15 classes, as discussed
    'nc': 15,
    'names': [
        'plane',
        'ship',
        'storage-tank',
        'baseball-diamond',
        'tennis-court',
        'basketball-court',
        'ground-track-field',
        'harbor',
        'bridge',
        'large-vehicle',
        'small-vehicle',
        'helicopter',
        'roundabout',
        'soccer-ball-field',
        'swimming-pool'
    ]
}

file_path = '/content/dota.yaml'
try:
    with open(file_path, 'w') as f:
        yaml.dump(data_yaml, f, sort_keys=False, default_flow_style=False)
    print(f"Successfully created '{file_path}'")
except Exception as e:
    print(f"Error creating YAML file: {e}")

print("\n--- ALL DATA PREPARATION IS COMPLETE ---")
print("You can now run Cell 2 to start training.")

!cat /content/DOTA_dataset/train/labels/P0001.txt

import os
import glob
from PIL import Image # Used to get image sizes
from tqdm import tqdm # A progress bar library

print("--- Starting Label Conversion (DOTA OBB to YOLO HBB) ---")

# This class list MUST match your dota.yaml file
CLASS_NAMES = [
    'plane', 'ship', 'storage-tank', 'baseball-diamond', 'tennis-court',
    'basketball-court', 'ground-track-field', 'harbor', 'bridge',
    'large-vehicle', 'small-vehicle', 'helicopter', 'roundabout',
    'soccer-ball-field', 'swimming-pool'
]

# Create a mapping from class name to class ID (e.g., 'ship' -> 1)
CLASS_MAP = {name: i for i, name in enumerate(CLASS_NAMES)}

def convert_dota_to_yolo(label_dir, image_dir):
    """
    Converts all DOTA OBB .txt files in a directory to YOLO HBB format.
    """
    label_files = glob.glob(os.path.join(label_dir, '*.txt'))
    if not label_files:
        print(f"Error: No .txt files found in {label_dir}")
        return 0

    print(f"Found {len(label_files)} label files to convert...")

    converted_count = 0
    for label_path in tqdm(label_files, desc=f"Converting {os.path.basename(label_dir)}"):
        # Get corresponding image path to find its size
        file_name = os.path.basename(label_path).split('.')[0]
        image_path = os.path.join(image_dir, file_name + '.png')

        if not os.path.exists(image_path):
            print(f"Warning: Image file not found for {label_path}, skipping.")
            continue

        try:
            # Get image dimensions
            with Image.open(image_path) as img:
                img_w, img_h = img.size
        except Exception as e:
            print(f"Error reading image {image_path}: {e}, skipping.")
            continue

        new_label_content = []
        with open(label_path, 'r') as f:
            lines = f.readlines()

        for line in lines:
            parts = line.strip().split()
            if len(parts) < 10: # Skip gsd/imagesource lines
                continue

            try:
                # DOTA format: x1 y1 x2 y2 x3 y3 x4 y4 class_name difficult
                coords = [float(p) for p in parts[:8]]
                class_name = parts[8]

                if class_name not in CLASS_MAP:
                    continue #['container-crane'-we are using 15 classes]

                class_id = CLASS_MAP[class_name]

                # Find the horizontal bounding box (HBB)
                x_coords = coords[0::2] # [x1, x2, x3, x4]
                y_coords = coords[1::2] # [y1, y2, y3, y4]

                x_min = min(x_coords)
                x_max = max(x_coords)
                y_min = min(y_coords)
                y_max = max(y_coords)

                # Convert to YOLO format (normalized)
                x_center = ((x_min + x_max) / 2) / img_w
                y_center = ((y_min + y_max) / 2) / img_h
                width = (x_max - x_min) / img_w
                height = (y_max - y_min) / img_h

                # Format the new line
                new_label_content.append(f"{class_id} {x_center} {y_center} {width} {height}\n")

            except Exception as e:
                print(f"Error processing line: '{line}' in {label_path}. Error: {e}")

        # Overwrite the original file with the new YOLO-formatted content
        with open(label_path, 'w') as f:
            f.writelines(new_label_content)

        converted_count += 1

    return converted_count

# --- Run the Conversion ---
base_dataset_path = "/content/DOTA_dataset"

# Convert training labels
train_label_dir = os.path.join(base_dataset_path, "train", "labels")
train_image_dir = os.path.join(base_dataset_path, "train", "images")
train_count = convert_dota_to_yolo(train_label_dir, train_image_dir)

# Convert validation labels
val_label_dir = os.path.join(base_dataset_path, "val", "labels")
val_image_dir = os.path.join(base_dataset_path, "val", "images")
val_count = convert_dota_to_yolo(val_label_dir, val_image_dir)

print("\n--- Conversion Complete ---")
print(f"Successfully converted {train_count} training label files.")
print(f"Successfully converted {val_count} validation label files.")
print("\nYou can now re-run the training cell (Cell 2).")

# 1. Install Ultralytics (if needed, but it's already installed)
!pip install ultralytics

# 2. Run Training (This will work now)
!yolo train \
  model=yolov8m.pt \
  data=/content/dota.yaml \
  epochs=100 \
  imgsz=1024 \
  batch=4 \
  cache=True \
  save_period=5 \
  project=DOTA_training \
  name=yolov8m_e100_i1024_run

import os
import shutil
import zipfile
import glob  # Import the glob module
from google.colab import files

print("Preparing files for download...")

# --- 1. Define the Path to Your Results ---
# This path comes directly from your training log.
results_dir = '/content/DOTA_training/yolov8m_e100_i1024_run2'
zip_filename = 'yolov8_dota_results.zip'

if not os.path.exists(results_dir):
    print(f"ERROR: Results directory not found at: {results_dir}")
    print("Please double-check the 'project' and 'name' used in your training command.")
else:
    # --- 2. List Important Files to Include ---
    files_to_zip = [
        # Model Weights
        os.path.join(results_dir, 'weights', 'best.pt'),
        os.path.join(results_dir, 'weights', 'last.pt'),

        # Key Performance Graphs
        os.path.join(results_dir, 'results.png'),
        os.path.join(results_dir, 'confusion_matrix.png'),
        os.path.join(results_dir, 'confusion_matrix_normalized.png'),
        os.path.join(results_dir, 'P_curve.png'), # Precision curve
        os.path.join(results_dir, 'R_curve.png'), # Recall curve
        os.path.join(results_dir, 'PR_curve.png'), # Precision-Recall curve
        os.path.join(results_dir, 'F1_curve.png'), # F1 score curve

        # Validation Predictions (First few batches)
        *glob.glob(os.path.join(results_dir, 'val_batch*_pred.jpg')),
        *glob.glob(os.path.join(results_dir, 'val_batch*_labels.jpg')),

        # Configuration and Results Data
        os.path.join(results_dir, 'args.yaml'), # Training arguments
        os.path.join(results_dir, 'results.csv') # Epoch-by-epoch results
    ]

    # Filter out files that might not exist
    existing_files = [f for f in files_to_zip if os.path.exists(f)]
    missing_files_count = len(files_to_zip) - len(existing_files)
    if missing_files_count > 0:
         print(f"Warning: {missing_files_count} expected result files were not found and will be skipped.")


    # --- 3. Create the Zip Archive ---
    print(f"\nCreating zip file: {zip_filename} ...")
    try:
        with zipfile.ZipFile(zip_filename, 'w') as zipf:
            for file in existing_files:
                # Add file to zip, using a relative path inside the zip
                zipf.write(file, arcname=os.path.relpath(file, '/content'))
        print("Zip file created successfully.")

        # --- 4. Trigger Browser Download ---
        print("Starting download...")
        files.download(zip_filename)
        print("Download initiated. Check your browser's download manager.")

    except Exception as e:
        print(f"Error creating or downloading zip file: {e}")

# 1. Install Ultralytics (if needed, but usually already installed)
!pip install ultralytics

# 2. Run Prediction on the Test Set
print("Running prediction on the test set...")
!yolo predict \
  model=/content/DOTA_training/yolov8m_e100_i1024_run2/weights/best.pt \
  source=/content/DOTA_dataset/test/images \
  imgsz=1024 \
  save=True \
  save_txt=True \
  save_conf=True \
  project=DOTA_prediction \
  name=yolov8m_test_run

import os
import glob
import random
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO # Import YOLO directly

print("Testing model on 3 random test images...")

# --- 1. Define Paths ---
model_path = '/content/DOTA_training/yolov8m_e100_i1024_run2/weights/best.pt' # Check if 'run2' is correct
original_image_dir = '/content/DOTA_dataset/test/images'
prediction_output_dir = '/content/DOTA_prediction/random_test_run' # Where predictions will be saved

# --- 2. Check if Model Exists ---
if not os.path.exists(model_path):
    print(f"ERROR: Model file not found at {model_path}")
else:
    # --- 3. Find All Original Test Images ---
    all_original_images = glob.glob(os.path.join(original_image_dir, '*.png'))

    if not all_original_images:
        print(f"ERROR: No original images found in {original_image_dir}")
    elif len(all_original_images) < 3:
        print(f"Warning: Found only {len(all_original_images)} test images. Testing on all of them.")
        selected_images = all_original_images
    else:
        # --- 4. Select 3 Random Images ---
        selected_images = random.sample(all_original_images, 3)
        print("Selected 3 random images:")
        for img_path in selected_images:
            print(f" - {os.path.basename(img_path)}")

    if selected_images:
        # --- 5. Run Prediction on Selected Images ---
        print("\nRunning YOLO prediction...")
        # Load the trained model
        model = YOLO(model_path)

        # Run prediction - YOLO automatically saves results
        # The 'project' and 'name' define the output directory
        results = model.predict(
            source=selected_images,
            imgsz=1024,
            save=True, # Saves images with boxes
            project='DOTA_prediction', # Main save folder
            name='random_test_run',    # Subfolder for this run
            exist_ok=True # Overwrite if the folder exists from a previous run
        )
        print(f"Prediction results saved to: {prediction_output_dir}")

        # --- 6. Display Side-by-Side ---
        print("\nDisplaying comparisons (Original vs. Detected):")
        fig, axes = plt.subplots(3, 1, figsize=(15, 24)) # 3 rows, 1 column

        for i, original_path in enumerate(selected_images):
            base_filename = os.path.basename(original_path)
            # Prediction image will be saved as JPG in the output dir
            predicted_path = os.path.join(prediction_output_dir, base_filename.replace('.png', '.jpg'))

            if not os.path.exists(predicted_path):
                 print(f"ERROR: Predicted image not found for {base_filename} at {predicted_path}")
                 axes[i].set_title(f"Error finding prediction for {base_filename}")
                 axes[i].axis('off')
                 continue

            try:
                img_orig = Image.open(original_path)
                img_pred = Image.open(predicted_path)

                # Ensure same size
                if img_orig.size != img_pred.size:
                    img_pred = img_pred.resize(img_orig.size)

                # Create combined image
                width1, height1 = img_orig.size
                combined_width = width1 * 2
                combined_height = height1
                new_img = Image.new('RGB', (combined_width, combined_height))

                # Paste images
                new_img.paste(img_orig, (0, 0))
                new_img.paste(img_pred, (width1, 0))

                # Display on subplot
                axes[i].imshow(new_img)
                axes[i].set_title(f"Comparison: {base_filename}")
                axes[i].axis('off')

            except Exception as e:
                print(f"Error processing {base_filename}: {e}")
                axes[i].set_title(f"Error processing {base_filename}")
                axes[i].axis('off')

        plt.tight_layout()
        plt.show()

import os
import glob
import random
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
from ultralytics import YOLO
import yaml # To load class names

print("Testing model on 2 random validation images and comparing with ground truth...")

# --- 1. Define Paths ---
model_path = '/content/DOTA_training/yolov8m_e100_i1024_run2/weights/best.pt' # Check if 'run2' is correct
val_image_dir = '/content/DOTA_dataset/val/images'
val_label_dir = '/content/DOTA_dataset/val/labels'
yaml_path = '/content/dota.yaml'
prediction_output_dir = '/content/DOTA_prediction/val_compare_run' # Temp dir for predictions

# --- 2. Load Class Names ---
try:
    with open(yaml_path, 'r') as f:
        data_yaml = yaml.safe_load(f)
        CLASS_NAMES = data_yaml['names']
    print(f"Loaded {len(CLASS_NAMES)} class names from {yaml_path}")
except Exception as e:
    print(f"ERROR: Could not load class names from {yaml_path}: {e}")
    CLASS_NAMES = [str(i) for i in range(15)] # Fallback to numbers
    print("Warning: Using numeric class IDs instead of names.")


# --- 3. Check if Model Exists ---
if not os.path.exists(model_path):
    print(f"ERROR: Model file not found at {model_path}")
else:
    # --- 4. Find All Validation Images ---
    all_val_images = glob.glob(os.path.join(val_image_dir, '*.png'))

    if not all_val_images:
        print(f"ERROR: No original images found in {val_image_dir}")
    elif len(all_val_images) < 2:
        print(f"Warning: Found only {len(all_val_images)} validation images. Testing on all of them.")
        selected_images = all_val_images
    else:
        # --- 5. Select 2 Random Images ---
        selected_images = random.sample(all_val_images, 2)
        print("\nSelected 2 random validation images:")
        for img_path in selected_images:
            print(f" - {os.path.basename(img_path)}")

    if selected_images:
        # --- 6. Run Prediction on Selected Images ---
        print("\nRunning YOLO prediction...")
        model = YOLO(model_path)
        results = model.predict(
            source=selected_images,
            imgsz=1024,
            save=True, # Saves images with predicted boxes
            project='DOTA_prediction',
            name='val_compare_run',
            exist_ok=True # Overwrite if needed
        )
        print(f"Prediction results saved to: {prediction_output_dir}")

        # --- 7. Function to Draw Ground Truth Boxes ---
        def draw_ground_truth(image_path, label_path, class_names):
            try:
                img = Image.open(image_path).convert("RGB")
                draw = ImageDraw.Draw(img)
                img_w, img_h = img.size

                # Try to load a commonly available font, fallback if not found
                try:
                    font = ImageFont.truetype("LiberationSans-Regular.ttf", 15)
                except IOError:
                    font = ImageFont.load_default()

                if not os.path.exists(label_path):
                    print(f"Warning: Label file not found for {image_path}")
                    return img # Return original image if no labels

                with open(label_path, 'r') as f:
                    lines = f.readlines()

                for line in lines:
                    parts = line.strip().split()
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:])

                    # Convert YOLO format (normalized center x,y,w,h) to absolute coordinates (xmin, ymin, xmax, ymax)
                    box_w = width * img_w
                    box_h = height * img_h
                    x_min = (x_center * img_w) - (box_w / 2)
                    y_min = (y_center * img_h) - (box_h / 2)
                    x_max = x_min + box_w
                    y_max = y_min + box_h

                    # Draw rectangle (outline)
                    label = class_names[class_id]
                    color = "lime" # Use a distinct color for ground truth
                    draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=2)

                    # Draw label text with background
                    text_size = draw.textbbox((0,0), label, font=font)
                    text_w = text_size[2] - text_size[0]
                    text_h = text_size[3] - text_size[1]
                    # Put background rectangle slightly above the box
                    text_bg_y_min = max(0, y_min - text_h - 2) # Ensure it doesn't go offscreen top
                    draw.rectangle([x_min, text_bg_y_min, x_min + text_w + 4, text_bg_y_min + text_h + 2], fill=color)
                    draw.text((x_min + 2, text_bg_y_min), label, fill="black", font=font)

                return img
            except Exception as e:
                print(f"Error drawing ground truth for {image_path}: {e}")
                # Return original image on error
                return Image.open(image_path).convert("RGB")


        # --- 8. Display Side-by-Side ---
        print("\nDisplaying comparisons (Ground Truth vs. Prediction):")
        fig, axes = plt.subplots(2, 1, figsize=(20, 20)) # 2 rows, 1 column, adjust size

        for i, original_path in enumerate(selected_images):
            base_filename = os.path.basename(original_path)
            label_filename = base_filename.replace('.png', '.txt')
            label_path = os.path.join(val_label_dir, label_filename)
            predicted_path = os.path.join(prediction_output_dir, base_filename.replace('.png', '.jpg')) # Prediction is saved as JPG

            if not os.path.exists(predicted_path):
                 print(f"ERROR: Predicted image not found for {base_filename}")
                 axes[i].set_title(f"Error finding prediction for {base_filename}")
                 axes[i].axis('off')
                 continue

            try:
                # Create image with Ground Truth boxes
                img_gt = draw_ground_truth(original_path, label_path, CLASS_NAMES)
                # Load image with Predicted boxes (already saved by YOLO)
                img_pred = Image.open(predicted_path)

                # Ensure same size
                if img_gt.size != img_pred.size:
                    img_pred = img_pred.resize(img_gt.size)

                # Create combined image
                width1, height1 = img_gt.size
                combined_width = width1 * 2
                combined_height = height1
                new_img = Image.new('RGB', (combined_width, combined_height))

                # Paste images
                new_img.paste(img_gt, (0, 0))
                new_img.paste(img_pred, (width1, 0))

                # Display on subplot
                axes[i].imshow(new_img)
                axes[i].set_title(f"Comparison: {base_filename}\n(Left: Ground Truth / Right: Prediction)")
                axes[i].axis('off')

            except Exception as e:
                print(f"Error processing {base_filename} for display: {e}")
                axes[i].set_title(f"Error displaying {base_filename}")
                axes[i].axis('off')

        plt.tight_layout(pad=2.0) # Add some padding between plots
        plt.show()

import os
import shutil
import zipfile
import glob  # Import the glob module
from google.colab import files

print("Preparing files for download...")

# --- 1. Define the Path to Your Results ---
# This path comes directly from your training log.
results_dir = '/content/DOTA_training/yolov8m_e100_i1024_run2'
zip_filename = 'yolov8_dota_results.zip'

if not os.path.exists(results_dir):
    print(f"ERROR: Results directory not found at: {results_dir}")
    print("Please double-check the 'project' and 'name' used in your training command.")
else:
    # --- 2. List Important Files to Include ---
    files_to_zip = [
        # Model Weights
        os.path.join(results_dir, 'weights', 'best.pt'),
        os.path.join(results_dir, 'weights', 'last.pt'),

        # Key Performance Graphs
        os.path.join(results_dir, 'results.png'),
        os.path.join(results_dir, 'confusion_matrix.png'),
        os.path.join(results_dir, 'confusion_matrix_normalized.png'),
        os.path.join(results_dir, 'P_curve.png'), # Precision curve
        os.path.join(results_dir, 'R_curve.png'), # Recall curve
        os.path.join(results_dir, 'PR_curve.png'), # Precision-Recall curve
        os.path.join(results_dir, 'F1_curve.png'), # F1 score curve

        # Validation Predictions (First few batches)
        *glob.glob(os.path.join(results_dir, 'val_batch*_pred.jpg')),
        *glob.glob(os.path.join(results_dir, 'val_batch*_labels.jpg')),

        # Configuration and Results Data
        os.path.join(results_dir, 'args.yaml'), # Training arguments
        os.path.join(results_dir, 'results.csv') # Epoch-by-epoch results
    ]

    # Filter out files that might not exist
    existing_files = [f for f in files_to_zip if os.path.exists(f)]
    missing_files_count = len(files_to_zip) - len(existing_files)
    if missing_files_count > 0:
         print(f"Warning: {missing_files_count} expected result files were not found and will be skipped.")


    # --- 3. Create the Zip Archive ---
    print(f"\nCreating zip file: {zip_filename} ...")
    try:
        with zipfile.ZipFile(zip_filename, 'w') as zipf:
            for file in existing_files:
                # Add file to zip, using a relative path inside the zip
                zipf.write(file, arcname=os.path.relpath(file, '/content'))
        print("Zip file created successfully.")

        # --- 4. Trigger Browser Download ---
        print("Starting download...")
        files.download(zip_filename)
        print("Download initiated. Check your browser's download manager.")

    except Exception as e:
        print(f"Error creating or downloading zip file: {e}")

import os
import glob
import random
from PIL import Image, ImageDraw, ImageFont
import matplotlib.pyplot as plt
from ultralytics import YOLO
import yaml # To load class names
import math # For subplot grid calculation

print("Running prediction and comparison for test and validation images...")

# --- Configuration ---
model_path = '/content/DOTA_training/yolov8m_e100_i1024_run2/weights/best.pt' # Check run number
test_image_dir = '/content/DOTA_dataset/test/images'
val_image_dir = '/content/DOTA_dataset/val/images'
val_label_dir = '/content/DOTA_dataset/val/labels'
yaml_path = '/content/dota.yaml'
prediction_project = 'DOTA_prediction'
test_run_name = 'random_test_compare'
val_run_name = 'random_val_compare'
test_prediction_dir = os.path.join('/content', prediction_project, test_run_name)
val_prediction_dir = os.path.join('/content', prediction_project, val_run_name)
num_test_samples = 5
num_val_samples = 10

# --- Load Class Names ---
try:
    with open(yaml_path, 'r') as f:
        data_yaml = yaml.safe_load(f)
        CLASS_NAMES = data_yaml['names']
    print(f"Loaded {len(CLASS_NAMES)} class names.")
except Exception as e:
    print(f"ERROR loading class names: {e}. Using numbers.")
    CLASS_NAMES = [str(i) for i in range(15)] # Fallback

# --- Load Model ---
if not os.path.exists(model_path):
    print(f"ERROR: Model file not found at {model_path}")
else:
    print("Loading trained model...")
    model = YOLO(model_path)

    # --- Process Test Images ---
    print(f"\n--- Processing {num_test_samples} Random Test Images ---")
    all_test_images = glob.glob(os.path.join(test_image_dir, '*.png'))
    if len(all_test_images) < num_test_samples:
        print(f"Warning: Only found {len(all_test_images)} test images.")
        selected_test_images = all_test_images
    else:
        selected_test_images = random.sample(all_test_images, num_test_samples)

    if selected_test_images:
        print("Running prediction on selected test images...")
        model.predict(
            source=selected_test_images, imgsz=1024, save=True,
            project=prediction_project, name=test_run_name, exist_ok=True
        )
        print(f"Test predictions saved to: {test_prediction_dir}")

        # Display Test Comparisons
        print("\nDisplaying Test Comparisons (Original vs. Predicted):")
        num_cols = 1 # Display vertically
        num_rows = num_test_samples
        fig_test, axes_test = plt.subplots(num_rows, num_cols, figsize=(15, 8 * num_rows))
        if num_rows == 1: axes_test = [axes_test] # Ensure axes_test is iterable

        for i, original_path in enumerate(selected_test_images):
            base_filename = os.path.basename(original_path)
            predicted_path = os.path.join(test_prediction_dir, base_filename.replace('.png', '.jpg'))

            if not os.path.exists(predicted_path):
                print(f"ERROR: Predicted image not found for {base_filename}")
                axes_test[i].set_title(f"Error finding prediction for {base_filename}")
                axes_test[i].axis('off')
                continue
            try:
                img_orig = Image.open(original_path)
                img_pred = Image.open(predicted_path)
                if img_orig.size != img_pred.size: img_pred = img_pred.resize(img_orig.size)

                combined_width = img_orig.width * 2
                new_img = Image.new('RGB', (combined_width, img_orig.height))
                new_img.paste(img_orig, (0, 0))
                new_img.paste(img_pred, (img_orig.width, 0))

                axes_test[i].imshow(new_img)
                axes_test[i].set_title(f"Test Image: {base_filename} (Left: Original / Right: Predicted)")
                axes_test[i].axis('off')
            except Exception as e:
                print(f"Error processing test image {base_filename}: {e}")
                axes_test[i].set_title(f"Error processing {base_filename}")
                axes_test[i].axis('off')

        plt.tight_layout(pad=3.0) # Add padding
        plt.show()

    # --- Process Validation Images ---
    print(f"\n--- Processing {num_val_samples} Random Validation Images ---")
    all_val_images = glob.glob(os.path.join(val_image_dir, '*.png'))
    if len(all_val_images) < num_val_samples:
        print(f"Warning: Only found {len(all_val_images)} validation images.")
        selected_val_images = all_val_images
    else:
        selected_val_images = random.sample(all_val_images, num_val_samples)

    if selected_val_images:
        print("Running prediction on selected validation images...")
        model.predict(
            source=selected_val_images, imgsz=1024, save=True,
            project=prediction_project, name=val_run_name, exist_ok=True
        )
        print(f"Validation predictions saved to: {val_prediction_dir}")

        # --- Function to Draw Ground Truth Boxes --- (Copied from previous step)
        def draw_ground_truth(image_path, label_path, class_names):
            try:
                img = Image.open(image_path).convert("RGB")
                draw = ImageDraw.Draw(img)
                img_w, img_h = img.size
                try:
                    font = ImageFont.truetype("LiberationSans-Regular.ttf", 15)
                except IOError:
                    font = ImageFont.load_default()

                if not os.path.exists(label_path): return img

                with open(label_path, 'r') as f: lines = f.readlines()
                for line in lines:
                    parts = line.strip().split()
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:])
                    box_w = width * img_w; box_h = height * img_h
                    x_min = (x_center * img_w) - (box_w / 2); y_min = (y_center * img_h) - (box_h / 2)
                    x_max = x_min + box_w; y_max = y_min + box_h
                    label = class_names[class_id]; color = "lime"
                    draw.rectangle([x_min, y_min, x_max, y_max], outline=color, width=2)
                    text_size = draw.textbbox((0,0), label, font=font)
                    text_w = text_size[2] - text_size[0]; text_h = text_size[3] - text_size[1]
                    text_bg_y_min = max(0, y_min - text_h - 2)
                    draw.rectangle([x_min, text_bg_y_min, x_min + text_w + 4, text_bg_y_min + text_h + 2], fill=color)
                    draw.text((x_min + 2, text_bg_y_min), label, fill="black", font=font)
                return img
            except Exception as e:
                print(f"Error drawing GT for {os.path.basename(image_path)}: {e}")
                return Image.open(image_path).convert("RGB") # Return original on error

        # Display Validation Comparisons
        print("\nDisplaying Validation Comparisons (Ground Truth vs. Predicted):")
        num_cols_val = 1 # Display vertically
        num_rows_val = num_val_samples
        fig_val, axes_val = plt.subplots(num_rows_val, num_cols_val, figsize=(15, 8 * num_rows_val))
        if num_rows_val == 1: axes_val = [axes_val] # Ensure axes_val is iterable

        for i, original_path in enumerate(selected_val_images):
            base_filename = os.path.basename(original_path)
            label_filename = base_filename.replace('.png', '.txt')
            label_path = os.path.join(val_label_dir, label_filename)
            predicted_path = os.path.join(val_prediction_dir, base_filename.replace('.png', '.jpg'))

            if not os.path.exists(predicted_path):
                print(f"ERROR: Predicted image not found for {base_filename}")
                axes_val[i].set_title(f"Error finding prediction for {base_filename}")
                axes_val[i].axis('off')
                continue
            try:
                img_gt = draw_ground_truth(original_path, label_path, CLASS_NAMES)
                img_pred = Image.open(predicted_path)
                if img_gt.size != img_pred.size: img_pred = img_pred.resize(img_gt.size)

                combined_width = img_gt.width * 2
                new_img = Image.new('RGB', (combined_width, img_gt.height))
                new_img.paste(img_gt, (0, 0))
                new_img.paste(img_pred, (img_gt.width, 0))

                axes_val[i].imshow(new_img)
                axes_val[i].set_title(f"Validation Image: {base_filename} (Left: Ground Truth / Right: Predicted)")
                axes_val[i].axis('off')
            except Exception as e:
                print(f"Error processing validation image {base_filename}: {e}")
                axes_val[i].set_title(f"Error processing {base_filename}")
                axes_val[i].axis('off')

        plt.tight_layout(pad=3.0) # Add padding
        plt.show()